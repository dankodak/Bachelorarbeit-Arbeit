\chapter{Einleitung}
\label{cha:Einleitung}


Unser Ziel ist es Lösungen von \acp{PDE} zu approximieren. Diese sind allgemein gegeben durch:
\begin{align*}
L u(x) &= f(x), x \in \Omega \\
B u(x) &= g(x), x \in \partial \Omega
\end{align*}
, wobei $\Omega \subset \mathbb{R}^n$, $L$ ein linearer, beschränkter Differentialoperator und $B$ ein linearer, beschränkter Auswertungsoperator ist.\\
Für den größten Teil dieser Arbeit werden wir folgende \ac{PDE} im $\mathbb{R}^2$ betrachten:
\begin{align*}
\Delta u(x) &= f(x), x \in \Omega \\
u(x) &= 0 , x \in \partial \Omega
\end{align*}

Es genügt die Nullrandbedingung zu betrachten, da jede \ac{PDE} auf eine mit Nullrandbedingung umgeformt werden kann.\\
HIER KOMMT DIE BEGRÜNDUNG!!

Wir wollen zur Approximation der \ac{PDE} einen interpolierenden Ansatz wählen. Dazu müssen wir die Interpolation zunächst verallgemeinern.

\begin{definition}
Sei $\Omega \subset \mathbb{R}^n$ eine nicht leere Menge, $\mathcal{H}$ ein Hilbertraum mit Funktionen $f:\Omega \rightarrow \mathbb{R}$, $u \in \mathcal{H}$  und $\Lambda_N := \{\lambda_1, \dots, \lambda_N\} \subset \mathcal{H}'$ eine Menge von linearen, stetigen und linear unabhängigen Funktionalen. Dann ist eine Funktion $s_u \in \mathcal{H}$ der gesuchte Interpolant von $u$, wenn gilt, dass
\begin{align*}
\lambda_i(u) = \lambda_i(s_u) , 1\le i \le N
\end{align*}
\end{definition}

\begin{example}
\begin{itemize}
\item
Sei $\Omega \subset \mathbb{R}^d$ ,$X_N := \{x_1, \dots, x_N\} \subset \Omega$ eine Menge von Punkten und $\mathcal{H}$ ein Hilbertraum mit Funktionen , in dem die Punktauswertungfunktionale $\delta_{x_i}(f) = f(x_i), 1\le i \le N$  stetig sind. Dann bekommen wir die Standardinterpolation mit $\Lambda_N := \{\delta_{x_1}, \dots,\delta_{x_N}\} \subset \mathcal{H}'$.
\begin{align*}
s(x_i) = \delta_{x_i}(s) = \delta_{x_i}(s_u) = s_u(x_i), 1\le i \le N
\end{align*}
\item
Mit $\lambda_i := \delta_{x_i} \circ D^a$ für einen Multiindex $a \in \mathbb{N}_0^d$ erhält man noch zusätzliche Informationen über die Ableitung der Funktion.
\item
Sei eine \ac{PDE} gegeben:
\begin{align*}
L u(x) &= f(x), x \in \Omega \\
B u(x) &= g(x), x \in \partial \Omega
\end{align*}
Sei $X_N \subset \Omega$ eine Menge an Kollokationspunkten. Dann möchten wir, dass $s_u$ die \ac{PDE} in den Punkten $X_N$ erfüllt, also:
\begin{align*}
L s_u(x_i) &= L u(x_i) = f(x_i), x_i \in \Omega \\
B s_u(x_i) &= B u(x_i) = g(x_i), x_i \in \partial \Omega
\end{align*}
\end{itemize}
\end{example}

Wir müssen einen geeigneten Ansatz wählen um das Interpolationsproblem zu lösen, also einen $N$-dimensionalen Unterraum $V_N := \text{span}\{\nu_1, \dots, \nu_N\} \subset \mathcal{H}$ und fordern, dass $s_u \in V_N$, also 
\begin{align*}
s_u(x) := \sum_{j=1}^N \alpha_j \nu_j(x), x \in \Omega, \alpha \in \mathbb{R}^N
\end{align*}
Also lassen sich die Interpolationsbedingungen schreiben als:
\begin{align*}
\lambda_i(u) = \lambda_i(s_u) = \sum_{j=1}^N \alpha_j \lambda_i(\nu_j)
\end{align*}
Diese lassen sich auch als lineares Gleichungssystem $A_\Lambda \alpha = b$ schreiben  mit $(A_\Lambda)_{i,j} := \lambda_i(\nu_j), b_i := \lambda_i(u)$.

\section{Standardkollokation}
Wir suchen jetzt nach geeigneten Ansatzfunktionen und einem Hilbertraum, in dem die Auswertungs- und Differentialfunktionale stetig sind. Dies führt uns zur Definition von Kern Funktionen mit denen wir einen Hilbertraum konstruieren werden, der uns das Geforderte liefern wird.

\begin{definition}
\label{Kern}
Sei $\Omega$ eine nicht leere Menge. Ein reeller Kern auf $\Omega$ ist eine symmetrische Funktion $K: \Omega \times \Omega \rightarrow \mathbb{R}$.\\
Für alle $N \in \mathbb{N}$ und für eine Menge $X_N = \{x_i\}_{i=1}^N$ ist die Kern Matrix (oder Gram'sche Matrix) $A:= A_{K,X_N} \in \mathbb{R}^{N \times N}$  definiert als $A:=[K(x_i, x_j)]_{i,j=1}^N$.\\
Ein Kern $K$ heißt \ac{PD} auf $\Omega$, wenn für alle $N \in \mathbb{N}$ und alle Mengen $X_N$ mit paarweise verschiedenen Elementen $x_{i=1}^N$ gilt, dass die Kern Matrix positiv definit ist. Der Kern $K$ heißt \ac{SPD}, falls die Kern Matrix strikt positiv definit ist.
\end{definition}

\begin{example} Sei $\Omega \subset \mathbb{R}^n$. Dann sind folgende Funktionen Kerne auf $\Omega$:\\
\begin{itemize}
\item $K(x,y) := \exp(-\gamma \|x-y\|),\gamma > 0$
\item $K(x,y) := (x,y)$
\end{itemize}
\end{example}

\begin{remark}
$\Omega$ kann eine beliebige Menge sein, es kann also auch ein Kern auf Strings oder Bildern definiert werden. Dies führt noch zu vielfältigeren Anwendungen.
\end{remark}

Wir kommen mit der Definition von Kernen direkt zu den gesuchten Hilberträumen.

\begin{definition}[Reproduzierender Kern Hilbertraum]
Sei $\Omega$ eine nicht leere Menge und $\mathcal{H}$ ein Hilbertraum mit Funktionen $f:\Omega \rightarrow \mathbb{R}$ und Skalarprodut $(\cdot, \cdot)_\mathcal{H}$. Dann nennt man $\mathcal{H}$ \ac{RKHR} auf $\Omega$, wenn eine Funktion $K:\Omega \times \Omega \rightarrow \mathbb{R}$ existiert, sodass
\begin{enumerate}
\item $K(\cdot, x) \in \mathcal{H}$ für alle $x \in \Omega$
\item $(f, K(\cdot,x))_\mathcal{H} = f(x)$ für alle $ x \in \Omega$, $f \in \mathcal{H}$
\end{enumerate}
\end{definition}

\begin{remark}
Die Funktion $K$ in einem \ac{RKHR} ist tatsächlich ein Kern nach Definition \ref{Kern}, welcher sogar positiv definit ist.
\end{remark}

Bei Interpolationsproblemen kommen wir jedoch aus der anderen Richung und haben zunächst einen Kern $K$ gegeben und wollen damit eine Funktion approximieren. Also stellt sich die Frage ob zu jedem Kern $K$ ein \ac{RKHR} existiert. Diese wird durch folgenden Satz beantwortet:

\begin{theorem}[Moore, Aronszajn]
Sei $\Omega$ eine nicht leere Menge und $K:\Omega \times \Omega \rightarrow \mathbb{R}$ ein positiv definiter Kern. Dann existiert genau ein \ac{RKHR} $\mathcal{H}_K (\Omega)$ mit reproduzierendem Kern $K$.
\end{theorem}
\begin{proof}
SIEHE SKRIPT!
\end{proof}

Mit diesem Wissen können wir uns erste Eigenschaften von \ac{RKHR} anschauen:

\begin{theorem}
\label{stetig}
Sei $\Omega$ eine nicht leere Menge und $\mathcal{H}$ ein Hilbertraum mit Funktionen $f: \Omega \rightarrow \mathbb{R}$. Dann gilt:
\begin{enumerate}
\item \label{stetig1} $\mathcal{H}$ ist genau dann ein \ac{RKHR}, wenn die Auswertungsfunktionale stetig sind.
\item \label{stetig2} Wenn $\mathcal{H}$ ein \ac{RKHR} mit Kern $K$ ist, dann ist $K(\cdot,x)$ der Riesz-Repräsentant des Funktionals $\delta_x \in \mathcal{H}'$.
\end{enumerate}
\end{theorem}

\begin{proof}
\begin{enumerate}
\item Für alle $f \in \mathcal{H}$ und alle $x \in \Omega$ gilt:
\begin{align*}
|f(x)| &= |(f, K(\cdot,x))_\mathcal{H}| \le \|f\|_\mathcal{H}\|K(\cdot,x)\|_\mathcal{H}\\
&= \|f\|_\mathcal{H} \sqrt{(K(\cdot,x),K(\cdot,x))_\mathcal{H}} = \|f\|_\mathcal{H} \sqrt{K(x,x)}
\end{align*}
, wobei für die erste und die letzte Gleichung die Reproduzierbarkeit des Kerns benutzt wurde.

Sei $\mathcal{H}$ ein \ac{RKHR}. Dann gilt mit dem eben gezeigten:
\begin{align*}
|\delta_x(f)| &= |f(x)| \le \|f\|_\mathcal{H} \sqrt{K(x,x)}\\
\Leftrightarrow \frac{|\delta_x(f)|}{\|f\|_\mathcal{H}} &\le \sqrt{K(x,x)}
\end{align*}
Also ist $\delta_x$ beschränkt und damit stetig.

Für die andere Richtung nehmen wir an, dass $\delta_x  \in \mathcal{H}'$ für alle $x \in \Omega$. Also existiert ein Riesz-Repräsentant $\nu_{\delta_x} \in \mathcal{H}$. Definieren wir $K(\cdot,x):= \nu_{\delta_x}$, dann ist $K$ ein Kern. Es ist klar, dass $K(\cdot,x) \in \mathcal{H}$ und nach der Definition des Riesz-Repräsentanten gilt:
\begin{align*}
(f, K(\cdot,x))_\mathcal{H} = (f, \nu_{\delta_x})_\mathcal{H} = \delta_x(f) = f(x)
\end{align*}
\item Die Behauptung folgt sofort aus der Reproduzierbarkeit von $K$, da $(f, K(\cdot,x))_\mathcal{H}= f(x)$ für alle $x \in \Omega$ und alle $f \in \mathcal{H}$ gilt.
\end{enumerate}
\end{proof}



Wir haben also gesehen, dass in einem \ac{RKHR} $\mathcal{H}_K$ die Auswertungsfunktionale stetig sind. Da wir uns mit Differentialgleichungen beschäftigen, wollen wir auch Ableitungen auswerten. Dafür benötigen wir, dass diese ebenfalls in $\mathcal{H}_K$ liegen.

\begin{theorem}
Sei $k \in \mathbb{N}$. Angenommen $\Omega \subset \mathbb{R}^n$ ist offen, K ist \ac{SPD} auf $\Omega$ und $K \in C^{2k}(\Omega \times \Omega)$. Dann gilt für alle Multiindizes $a \in \mathbb{N}_0^d$ mit $|a| \le k$ und alle $x \in \Omega$, dass $D_2^a K(\cdot , x) \in \mathcal{H}_K(\Omega)$.

Außerdem gilt für alle $f \in \mathcal{H}_K(\Omega)$:
\begin{align*}
D^a f(x) = \left(f,D_2^a K(\cdot,x)\right)_{\mathcal{H}_K(\Omega)}
\end{align*}
und damit dass $\lambda := \delta_x \circ D^a$ stetig ist.
\end{theorem}

\begin{proof}
BEWEIS IST LANG

Der Beweis der Stetigkeit von $\lambda := \delta_x \circ D^a$ verläuft komplett analog zum Beweis von \ref{stetig}.\ref{stetig1}.
\end{proof}

In Satz \ref{stetig} haben wir gesehen, wie der Riesz-Repräsentant des Auswertungsfunktionals aussieht. Dies wollen wir jetzt auf alle Funktionale verallgemeinern.

\begin{theorem}
\label{Riesz}
Sei $K$ ein \ac{SPD} Kern auf $\Omega \neq \emptyset$. Sei $\lambda \in \mathcal{H}_K (\Omega)'$. Dann ist $\lambda^y K(\cdot,y) \in \mathcal{H}_k(\Omega)$ und es gilt $\lambda(f) = \left(f,\lambda^y K(\cdot,y)\right)_{\mathcal{H}_K(\Omega)}$ für alle $f \in \mathcal{H}_K(\Omega)$, also ist $\lambda^y K(\cdot,y)$ der Riesz-Repräsentant von $\lambda$.
\end{theorem}

\begin{proof}
Da $\lambda \in \mathcal{H}_K(\Omega)$ existiert ein Riesz-Repräsentant $\nu_\lambda \in \mathcal{H}_K(\Omega)$ mit $\lambda (f) = \left(f, \nu_\lambda\right)_{\mathcal{H}_K(\Omega)}$. Außerdem ist $f_x(y) := K(x,y)$ für alle $x \in \Omega$ eine Funktion in $\mathcal{H}_K (\Omega)$. Dann bekommen wir:
\begin{align*}
\lambda^y K(x,y) = \lambda(f_x) = \left(f_x, \nu_\lambda\right)_{\mathcal{H}_K (\Omega)} = \left(K(\cdot,x), \nu_\lambda\right)_{\mathcal{H}_K (\Omega)} = \nu_\lambda(x)
\end{align*}
Damit gilt $\nu_\lambda(\cdot) = \lambda^y K(\cdot,y)$ und auch $\lambda^y K(\cdot,y) \in \mathcal{H}_K (\Omega)$.
\end{proof}

Jetzt fehlt nur noch die lineare Unabhängigkeit aller verwendeten Funktionale. Zunächst die der Auswertungsfunktionale:
\begin{theorem}
Sei $\Omega$ eine nicht leere Menge und $\mathcal{H}$ ein \ac{RKHR} mit Kern $K$. Dann sind $\{\delta_x,x\in \Omega\}$ genau dann linear unabhängig, wenn $K$ \ac{SPD} ist.
\end{theorem}

\begin{proof}
Seien $\lambda_1, \dots, \lambda_n \in \mathcal{H}'$ und $\nu_{\lambda_1},\dots, \nu_{\lambda_n} \in \mathcal{H}$ die dazugehörigen Riesz Repräsentanten. Diese sind linear abhängig, wenn ein $\alpha \in \mathbb{R}^n$ existiert mit $\lambda := \sum_{i=1}^n \alpha_i \lambda_i = 0$, also dass $\lambda(f) = 0$ für alle $f \in \mathcal{H}$. Das gilt genau dann, wenn die Riesz Repräsentanten linear abhängig sind, da
\begin{align*}
0 = \lambda(f) = \sum_{i=1}^n \alpha_i \lambda_i(f) = \sum_{i=1}^n \alpha_i \left( \nu_{\lambda_i},f\right)_\mathcal{H} = \left( \sum_{i=1}^n \alpha_i \nu_{\lambda_i}, f \right)_\mathcal{H}
\end{align*}
Also gilt nach \ref{stetig}.\ref{stetig2}, dass $\{\delta_x,x\in \Omega\}$ genau dann linear unabhängig sind, wenn $\{K(\cdot,x) , x \in \Omega\}$ linear unabhängig sind.

Um die strikte positive Definitheit nachzuweisen, betrachten wir die Matrix $A=[K(x_i, x_j)]_{i,j=1}^N$ für paarweise unterschiedliche Punkte $x_i, 1 \le i \le N$. Sei also $\beta \in \mathbb{R}^n, \beta \neq 0$. Dann gilt:
\begin{align*}
\beta^T A \beta &= \sum_{i,j=1}^n \beta_i \beta_j K(x_i, x_j)\\
&= \sum_{i,j=1}^n \beta_i  \beta_j \left(K(\cdot, x_i),K(\cdot,x_j)\right)_\mathcal{H}\\
&= \left( \sum_{i=1}^n \beta_i K(\cdot,x_i),\sum_{j=1}^n \beta_j K(\cdot, x_j) \right)_\mathcal{H}\\
&= \left\| \sum_{i=1}^n \beta_i K(\cdot, x_i) \right\|_\mathcal{H}^2 > 0
\end{align*}
Für die letzte strikte Ungleichung benötigen wir die lineare Unabhängigkeit. Also gilt, dass K \ac{SPD} ist, wenn $\{\delta_x,x\in \Omega\}$ linear unabhängig sind.
\end{proof}

Und jetzt die der Auswertungen der Ableitungen:

\begin{theorem}
\label{linUn}
Sei $K$ ein translationsinvarianter Kern auf $\mathbb{R}^d$, also $K(x,y) = \Phi (x-y)$ für alle $x,y \in \mathbb{R}^d$. Sei $k \in \mathbb{N}$ und angenommen, dass $\Phi \in L_1(\mathbb{R}^d) \cap C^{2k}(\mathbb{R}^d)$. Sei $a_1, \dots, a_N \in \mathbb{N}_0^d$ mit $|a_i| \le k$ und sei $X_N \subset \mathbb{R}^d$. Angenommen, dass $a_i \neq a_j$, wenn $x_i = x_j$, dann sind die Funktionale $\Lambda_N := \{\lambda_1, \dots, \lambda_N\}, \lambda_i := \delta_{x_i} \circ D^{a_i}$ linear unabhängig in $\mathcal{H}_K(\mathbb{R}^d)$.
\end{theorem}

\begin{proof}
BUCH ODER SKRIPT
\end{proof}


Damit haben wir alle nötigen Werkzeuge um die Interpolation durchzuführen. Wir haben Ansatzfunktionen $K$, den dazugehörigen Hilbertraum $\mathcal{H}_K(\Omega)$, die Stetigkeit und lineare Unabhängigkeit aller benötigten Operatoren. Jetzt müssen wir nur noch einen geeigneten Ansatz wählen.
\subsection{Symmetrische Kollokation}
Sei wieder $\Omega \subset \mathbb{R}^n$ offen und beschränkt, $L,B$ lineare Differentialoperatoren, $K$ ein positiv definiter Kern und folgendes Problem gegeben:
\begin{align*}
L u(x) &= f(x), x \in \Omega \\
B u(x) &= g(x), x \in \partial \Omega
\end{align*}
Für ein $N \in \mathbb{N}$ betrachten wir die Menge $X_N \subset \Omega$, die wir in $N_{in}$ Punkte im Inneren und $N_{bd}$ Punkte auf dem Rand aufteilen. Also haben wir die beiden Mengen
\begin{align*}
X_{in} &= X_N \cap \Omega\\
X_{bd} &= X_N \cap \partial \Omega
\end{align*}
Wir definieren die Menge $\Lambda_N = \{\lambda_1, \dots, \lambda_N\}$ an linearen Funktionalen mit
\begin{align*}
\lambda_i =
\begin{cases}
\delta_{x_i} \circ L & x_i \in \Omega\\
\delta_{x_i} \circ B & x_i \in \partial \Omega
\end{cases}
\end{align*}
Wir wissen aus Satz \ref{stetig}, dass in $\mathcal{H}_K(\Omega)$ alle $\lambda_i$ stetig und aus Satz \ref{linUn}, dass sie linear unabhängig sind. Als Ansatzfunktionen, also den Unterraum $V_N \subset \mathcal{H}_K(\Omega)$, wählen wir die Riesz Repräsentanten der $\lambda_i$:
\begin{align*}
V_N &= \text{span} \{\lambda_1^y K(x,y), \dots , \lambda_N^y K(x,y)\}\\
&= \text{span} \{(\delta_{x_1} \circ L)^y K(x,y), \dots, (\delta_{x_{N_in}} \circ L)^y K(x,y), (\delta_{x_{N_{in} + 1}} \circ B)^y K(x,y), \dots, (\delta_{x_{N}} \circ B)^y K(x,y)\}\\
&=: \text{span} \{\nu_1, \dots, \nu_N\}
\end{align*}
, wobei der hochgesetzte Index y bedeutet, dass der Operator auf das zweite Argument angewandt wird.

Damit bekommen wir folgenden Interpolanten:
\begin{align*}
s_u(x) &= \sum_{j=1}^N \alpha_j \lambda_j^y K(x,y)\\
&= \sum_{j=1}^{N_{in}} \alpha_j (\delta_{x_j} \circ L)^y K(x,y) + \sum_{j=N_{in}}^{N} \alpha_j (\delta_{x_j} \circ L)^y K(x,y)
\end{align*}
Die $\alpha_j$ erhält man als Lösung des \ac{LGS} $A \alpha = b$ mit $A_{i,j} := (\nu_i,\nu_j)_{\mathcal{H}_K}$, da
\begin{align*}
\left<\lambda_i, s_u\right> = \left< \lambda_i, \sum_{j=1}^N \alpha_j \nu_j \right> = \sum_{j=1}^N \alpha_j \left< \lambda_i,\nu_j\right> \overset{\ref{Riesz}}{=} \sum_{j=1}^N \alpha_j \left(\nu_j, \nu_i\right)
\end{align*},
 also
\begin{align*}
\begin{pmatrix}
A_{L,L} & A_{L,B} \\ 
A_{L,B}^T & A_{B,B}
\end{pmatrix} 
\alpha =
\begin{pmatrix}
b_L \\ 
b_B
\end{pmatrix} 
\end{align*}
mit
\begin{align*}
(A_{L,L})_{i,j} &= (\delta_{x_i} \circ L)^x(\delta_{x_j} \circ L)^y K(x,y),x_i, x_j \in X_{in}\\
(A_{L,B})_{i,j} &= (\delta_{x_i} \circ L)^x(\delta_{x_j} \circ B)^y K(x,y),x_i \in X_{in}, x_j \in X_{bd} \\
(A_{B,B})_{i,j} &= (\delta_{x_i} \circ B)^x(\delta_{x_j} \circ B)^y K(x,y), x_i, x_j \in X_{bd}
\end{align*}
und
\begin{align*}
(b_L)_i &= f(x_i), x_i \in X_{in}\\
(b_B)_i &= g(x_i), x_i \in X_{bd}
\end{align*}
Das \ac{LGS} ist lösbar, da A offensichtlich symmetrisch und positiv definit ist, da:
\begin{align*}
\alpha^T A \alpha = \sum_{i,j = 1}^N \alpha_i \alpha_j (\nu_i, \nu_j)_{\mathcal{H}_K} = \left(\sum_{i=1}^N \alpha_i \nu_i, \sum_{j=1}^N \alpha_j \nu_j \right)_{\mathcal{H}_K} = \left\| \sum_{i=1}^N \alpha_i \nu_i \right\|_{\mathcal{H}_K}^2 > 0
\end{align*}
Für die letzte Abschätzung benutzen wir die lineare Unabhängigkeit der Funktionale aus Satz \ref{linUn}.
\subsection{Nicht-Symmetrische Kollokation}